<!DOCTYPE html>
<html>
<head>
    <title>AI Science Expo - Scanner</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-database.js"></script>
    <style>
        body { margin: 0; background: #000; overflow: hidden; font-family: 'Segoe UI', sans-serif; }
        #status { position: absolute; top: 10%; width: 100%; text-align: center; color: #00ffff; font-weight: bold; font-size: 1.5rem; text-shadow: 0 0 10px #00ffff; z-index: 10; }
        video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
    </style>
</head>
<body>
    <div id="status">READY FOR SCAN</div>
    <video id="input_video" playsinline></video>
    <canvas id="output_canvas"></canvas>

    <script>
        const firebaseConfig = { databaseURL: "https://palm-scanner-expo-default-rtdb.europe-west1.firebasedatabase.app/" };
        firebase.initializeApp(firebaseConfig);
        const database = firebase.database();

        const videoElement = document.getElementById('input_video');
        const canvasElement = document.getElementById('output_canvas');
        const canvasCtx = canvasElement.getContext('2d');
        let scanY = 0; // For the moving laser effect

        const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
        hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.7 });

        hands.onResults((results) => {
            canvasElement.width = videoElement.videoWidth;
            canvasElement.height = videoElement.videoHeight;
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                const lm = results.multiHandLandmarks[0];
                drawProLines(lm);
                drawLaserScan();
                database.ref('palm_reading_data').update({ scanning: true });
                document.getElementById('status').innerText = "ANALYZING BIOMETRICS...";
            } else {
                document.getElementById('status').innerText = "PLACE PALM IN VIEW";
            }
        });

        function drawLaserScan() {
            const w = canvasElement.width; const h = canvasElement.height;
            scanY = (scanY + 15) % h;
            canvasCtx.strokeStyle = "rgba(0, 255, 255, 0.8)";
            canvasCtx.lineWidth = 3;
            canvasCtx.shadowBlur = 20;
            canvasCtx.shadowColor = "#00ffff";
            canvasCtx.beginPath();
            canvasCtx.moveTo(0, scanY);
            canvasCtx.lineTo(w, scanY);
            canvasCtx.stroke();
        }

        function drawProLines(lm) {
            const w = canvasElement.width; const h = canvasElement.height;
            canvasCtx.lineWidth = 5;
            canvasCtx.lineCap = "round";
            
            // --- HEART LINE (Pink/Purple) ---
            canvasCtx.strokeStyle = "#ff00ff"; canvasCtx.beginPath();
            canvasCtx.moveTo(lm[17].x * w, lm[17].y * h + 20);
            canvasCtx.bezierCurveTo(lm[13].x * w, lm[13].y * h, lm[9].x * w, lm[9].y * h, lm[5].x * w, lm[5].y * h + 20);
            canvasCtx.stroke();

            // --- HEAD LINE (Yellow) ---
            canvasCtx.strokeStyle = "#ffff00"; canvasCtx.beginPath();
            canvasCtx.moveTo(lm[1].x * w, lm[1].y * h);
            canvasCtx.lineTo(lm[13].x * w, lm[13].y * h + 40);
            canvasCtx.stroke();

            // --- LIFE LINE (Green) ---
            canvasCtx.strokeStyle = "#00ff00"; canvasCtx.beginPath();
            canvasCtx.moveTo(lm[1].x * w, lm[1].y * h);
            canvasCtx.quadraticCurveTo(lm[2].x * w, lm[5].y * h + 50, lm[0].x * w, lm[0].y * h - 20);
            canvasCtx.stroke();
        }

        const camera = new Camera(videoElement, {
            onFrame: async () => { await hands.send({image: videoElement}); },
            facingMode: 'environment', width: 1280, height: 720
        });
        camera.start();
    </script>
</body>
</html>

